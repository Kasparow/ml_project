{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 20news data with python\n",
    "\n",
    "The data is in form (group, word, frequency). This structure follows the COO sparse matrix format.\n",
    "\n",
    "The last column (frequency) is not used in this project.\n",
    "\n",
    "Finally print details to make sure loading data stats from here results the same values as provided by R example demo(0).\n",
    "\n",
    "__R Demo(0) stats__:\n",
    "- Number of groups: 20\n",
    "- Number of words: 53975\n",
    "- Number of documents: 11269\n",
    "- Number of word-doc pairs: 1467345\n",
    "- Density: 0.002412427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix, vstack\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', '1')\n"
     ]
    }
   ],
   "source": [
    "def load_20news_data(path_pfix=\"data/20news/\"):\n",
    "    X = []\n",
    "    with open(f\"{path_pfix}train.data\", \"r\") as f:\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            line = line.split()\n",
    "            assert len(line) == 3, f\"line.split() returned incorrect number of elements: {len(line)} != 3\"\n",
    "            X.append(tuple(line[:2]))\n",
    "    \n",
    "    f = open(f\"{path_pfix}train.label\", \"r\")\n",
    "    y = [label.strip() for label in f.readlines()]\n",
    "    f.close()\n",
    "    \n",
    "    f = open(f\"{path_pfix}vocabulary.txt\", \"r\")\n",
    "    vocab = [token.strip() for token in f.readlines()]\n",
    "    f.close()\n",
    "    print(X[0])\n",
    "    return np.array(X, dtype=int), np.array(y, dtype=int), vocab\n",
    "\n",
    "\n",
    "X, y, vocab = load_20news_data()\n",
    "prev_docid = None\n",
    "docid_count = 0\n",
    "for x in X:\n",
    "    if x[0] != prev_docid:\n",
    "        docid_count += 1\n",
    "        prev_docid = x[0]\n",
    "\n",
    "assert docid_count == len(y), \\\n",
    "    \"Number of doc_ids and labels should be equal, got {docid_count} doc_ids and {len(y)} labels.\"\n",
    "\n",
    "groups = [\n",
    "    'alt.atheism', \n",
    "    'comp.graphics',    \n",
    "    'comp.os.ms-windows.misc', \n",
    "    'comp.sys.ibm.pc.hardware', \n",
    "    'comp.sys.mac.hardware', \n",
    "    'comp.windows.x', \n",
    "    'misc.forsale', \n",
    "    'rec.autos', \n",
    "    'rec.motorcycles', \n",
    "    'rec.sport.baseball', \n",
    "    'rec.sport.hockey', \n",
    "    'sci.crypt', \n",
    "    'sci.electronics', \n",
    "    'sci.med', \n",
    "    'sci.space', \n",
    "    'soc.religion.christian', \n",
    "    'talk.politics.guns',\n",
    "    'talk.politics.mideast', \n",
    "    'talk.politics.misc', \n",
    "    'talk.religion.misc'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Number of groups: 20\n",
      "• Number of words: 53975\n",
      "• Number of documents: 11269\n",
      "• Number of word-doc-pairs: 1467345\n",
      "• Density: 0.002412427\n"
     ]
    }
   ],
   "source": [
    "print(f\"• Number of groups: {len(groups)}\")\n",
    "print(f\"• Number of words: {len(vocab)}\")\n",
    "print(f\"• Number of documents: {docid_count}\")\n",
    "print(f\"• Number of word-doc-pairs: {len(X)}\")\n",
    "print(f\"• Density: {round(len(X)/(docid_count*len(vocab)), 9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynp = np.array(y, dtype=int)\n",
    "group_index_ranges = []  # stores 2-tuples like (start_index, end_index) for each of the 20 groups\n",
    "train_index_ranges = []\n",
    "test_index_ranges = []\n",
    "for i in range(1, 21):\n",
    "    mask = (ynp == i)\n",
    "    idx_range = np.where(mask)[0]\n",
    "    split_idx = int((idx_range[-1]-idx_range[0])*0.9+idx_range[0])\n",
    "    group_index_ranges.append((idx_range[0], idx_range[-1]))\n",
    "    train_index_ranges.append((idx_range[0], split_idx))\n",
    "    test_index_ranges.append((split_idx, idx_range[-1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 431),\n",
       " (480, 1002),\n",
       " (1061, 1574),\n",
       " (1633, 2160),\n",
       " (2220, 2736),\n",
       " (2795, 3326),\n",
       " (3387, 3909),\n",
       " (3969, 4500),\n",
       " (4561, 5096),\n",
       " (5157, 5690),\n",
       " (5751, 6288),\n",
       " (6349, 6882),\n",
       " (6943, 7474),\n",
       " (7534, 8067),\n",
       " (8128, 8660),\n",
       " (8721, 9259),\n",
       " (9320, 9809),\n",
       " (9865, 10371),\n",
       " (10429, 10845),\n",
       " (10893, 11230)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(431, 480),\n",
       " (1002, 1061),\n",
       " (1574, 1633),\n",
       " (2160, 2220),\n",
       " (2736, 2795),\n",
       " (3326, 3387),\n",
       " (3909, 3969),\n",
       " (4500, 4561),\n",
       " (5096, 5157),\n",
       " (5690, 5751),\n",
       " (6288, 6349),\n",
       " (6882, 6943),\n",
       " (7474, 7534),\n",
       " (8067, 8128),\n",
       " (8660, 8721),\n",
       " (9259, 9320),\n",
       " (9809, 9865),\n",
       " (10371, 10429),\n",
       " (10845, 10893),\n",
       " (11230, 11269)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conditional probability tables\n",
    "\n",
    "\"Estimate the probability that a document from the given group contains the word word.\"\n",
    "\n",
    "Here we don't care about the word frequencies in documents, just the binary occurrence. Basically you need to count the number of documents in each group that has each word.\n",
    "\n",
    "`p(w|g) = #(docs_having_word and docs_in_group) / #docs_in_group`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y-labels are in array thats length is the number of documents in the dataset. X on the other hand is currently in (implicit) sparse matrix format where first index indicates the document and second index the word. Construct a proper sparse matrix from X and concatenate Y to it.\n",
    "\n",
    "The dataset was intended to be used with R and for that reason the indexing starts with 1 instead of 0. Remove the first row and first column from resulting sparse matrix\n",
    "\n",
    "After the data in X is transformed, the documents can be directly aggregated based on group indexes given in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11270, 53976)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "X_csr = csr_matrix((np.ones(X.shape[0]), (X[:, 0], X[:, 1])))\n",
    "print(X_csr.shape)\n",
    "print(X_csr[:, 0].sum() == 0)\n",
    "print(X_csr[0, :].sum() == 0)\n",
    "X_csr = X_csr[:, range(1, X_csr.shape[1])]  # remove first column as its all-zeroes\n",
    "X_csr = X_csr[range(1, X_csr.shape[0]), :]  # remove first row as its all-zeroes\n",
    "assert X_csr.sum() == X.shape[0], f\"# of elements in sparse csr matrix does not match with the original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269, 53975)\n",
      "1467345.0\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X_csr.shape)\n",
    "print(X_csr.sum())\n",
    "print(X_csr[:, 0].sum() == 0)\n",
    "print(X_csr[0, :].sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "[[ 3. 33. 74.  4. 35. 30.  4.  1. 15. 48.]]\n",
      "[[7.35213028e-05 6.24931074e-04 1.37852443e-03 9.19016285e-05\n",
      "  6.61691725e-04 5.69790097e-04 9.19016285e-05 3.67606514e-05\n",
      "  2.94085211e-04 9.00635959e-04]]\n",
      "2\n",
      "\n",
      "522\n",
      "[[10. 34.  0.  7.  9. 39.  7.  5. 51.  3.]]\n",
      "[[2.01845973e-04 6.42237187e-04 1.83496339e-05 1.46797071e-04\n",
      "  1.83496339e-04 7.33985357e-04 1.46797071e-04 1.10097804e-04\n",
      "  9.54180964e-04 7.33985357e-05]]\n",
      "2\n",
      "\n",
      "513\n",
      "[[ 9. 39.  0. 10. 13. 32.  2.  2. 81.  0.]]\n",
      "[[1.83526648e-04 7.34106592e-04 1.83526648e-05 2.01879313e-04\n",
      "  2.56937307e-04 6.05637939e-04 5.50579944e-05 5.50579944e-05\n",
      "  1.50491851e-03 1.83526648e-05]]\n",
      "2\n",
      "\n",
      "527\n",
      "[[ 6. 18.  0.  0.  5. 41.  2.  1. 24.  0.]]\n",
      "[[1.28435654e-04 3.48611060e-04 1.83479505e-05 1.83479505e-05\n",
      "  1.10087703e-04 7.70613922e-04 5.50438516e-05 3.66959011e-05\n",
      "  4.58698763e-04 1.83479505e-05]]\n",
      "2\n",
      "\n",
      "516\n",
      "[[ 4. 19.  0.  1.  0. 35.  0.  0. 24.  0.]]\n",
      "[[9.17582720e-05 3.67033088e-04 1.83516544e-05 3.67033088e-05\n",
      "  1.83516544e-05 6.60659558e-04 1.83516544e-05 1.83516544e-05\n",
      "  4.58791360e-04 1.83516544e-05]]\n",
      "2\n",
      "\n",
      "531\n",
      "[[13. 46.  0. 18.  9. 28. 11.  3. 61.  0.]]\n",
      "[[2.56852457e-04 8.62290390e-04 1.83466040e-05 3.48585477e-04\n",
      "  1.83466040e-04 5.32051517e-04 2.20159249e-04 7.33864162e-05\n",
      "  1.13748945e-03 1.83466040e-05]]\n",
      "2\n",
      "\n",
      "522\n",
      "[[ 0. 18.  0.  2.  1. 23.  0.  0. 15.  3.]]\n",
      "[[1.83496339e-05 3.48643045e-04 1.83496339e-05 5.50489018e-05\n",
      "  3.66992678e-05 4.40391214e-04 1.83496339e-05 1.83496339e-05\n",
      "  2.93594143e-04 7.33985357e-05]]\n",
      "2\n",
      "\n",
      "531\n",
      "[[ 7. 36.  0.  0.  8. 66.  7.  3. 16.  0.]]\n",
      "[[1.46772832e-04 6.78824350e-04 1.83466040e-05 1.83466040e-05\n",
      "  1.65119436e-04 1.22922247e-03 1.46772832e-04 7.33864162e-05\n",
      "  3.11892269e-04 1.83466040e-05]]\n",
      "2\n",
      "\n",
      "535\n",
      "[[ 4. 32.  0.  2.  2. 65.  3.  1.  3.  0.]]\n",
      "[[9.17262888e-05 6.05393506e-04 1.83452578e-05 5.50357733e-05\n",
      "  5.50357733e-05 1.21078701e-03 7.33810310e-05 3.66905155e-05\n",
      "  7.33810310e-05 1.83452578e-05]]\n",
      "2\n",
      "\n",
      "533\n",
      "[[  1.  24.   0.   2.   1. 145.   1.   0.   2.   0.]]\n",
      "[[3.66918617e-05 4.58648272e-04 1.83459309e-05 5.50377926e-05\n",
      "  3.66918617e-05 2.67850591e-03 3.66918617e-05 1.83459309e-05\n",
      "  5.50377926e-05 1.83459309e-05]]\n",
      "2\n",
      "\n",
      "537\n",
      "[[  1.  35.   0.   0.   1. 120.   1.   6.   3.   0.]]\n",
      "[[3.66891694e-05 6.60405048e-04 1.83445847e-05 1.83445847e-05\n",
      "  3.66891694e-05 2.21969475e-03 3.66891694e-05 1.28412093e-04\n",
      "  7.33783387e-05 1.83445847e-05]]\n",
      "2\n",
      "\n",
      "533\n",
      "[[29. 55.  0.  7. 20. 53. 22.  4. 39.  0.]]\n",
      "[[5.50377926e-04 1.02737213e-03 1.83459309e-05 1.46767447e-04\n",
      "  3.85264548e-04 9.90680267e-04 4.21956410e-04 9.17296544e-05\n",
      "  7.33837235e-04 1.83459309e-05]]\n",
      "2\n",
      "\n",
      "531\n",
      "[[ 1. 18.  0.  1.  4. 21.  3.  1. 21.  0.]]\n",
      "[[3.66932081e-05 3.48585477e-04 1.83466040e-05 3.66932081e-05\n",
      "  9.17330202e-05 4.03625289e-04 7.33864162e-05 3.66932081e-05\n",
      "  4.03625289e-04 1.83466040e-05]]\n",
      "2\n",
      "\n",
      "533\n",
      "[[ 5. 24.  0.  8.  8. 45.  1.  4.  8.  0.]]\n",
      "[[1.10075585e-04 4.58648272e-04 1.83459309e-05 1.65113378e-04\n",
      "  1.65113378e-04 8.43912820e-04 3.66918617e-05 9.17296544e-05\n",
      "  1.65113378e-04 1.83459309e-05]]\n",
      "2\n",
      "\n",
      "532\n",
      "[[20. 53.  0. 15. 10. 61. 20.  7. 14.  0.]]\n",
      "[[3.85271616e-04 9.90698442e-04 1.83462675e-05 2.93540279e-04\n",
      "  2.01808942e-04 1.13746858e-03 3.85271616e-04 1.46770140e-04\n",
      "  2.75194012e-04 1.83462675e-05]]\n",
      "2\n",
      "\n",
      "538\n",
      "[[ 0. 61. 10.  5. 11. 65.  0.  0. 11. 37.]]\n",
      "[[1.83442482e-05 1.13734339e-03 2.01786730e-04 1.10065489e-04\n",
      "  2.20130978e-04 1.21072038e-03 1.83442482e-05 1.83442482e-05\n",
      "  2.20130978e-04 6.97081430e-04]]\n",
      "2\n",
      "\n",
      "489\n",
      "[[ 0. 24.  0.  6. 10. 82.  2.  0. 14.  0.]]\n",
      "[[1.83607521e-05 4.59018801e-04 1.83607521e-05 1.28525264e-04\n",
      "  2.01968273e-04 1.52394242e-03 5.50822562e-05 1.83607521e-05\n",
      "  2.75411281e-04 1.83607521e-05]]\n",
      "2\n",
      "\n",
      "506\n",
      "[[ 8. 67.  0.  7.  2. 97.  5. 19.  9.  1.]]\n",
      "[[1.65195206e-04 1.24814155e-03 1.83550229e-05 1.46840183e-04\n",
      "  5.50650686e-05 1.79879224e-03 1.10130137e-04 3.67100457e-04\n",
      "  1.83550229e-04 3.67100457e-05]]\n",
      "2\n",
      "\n",
      "416\n",
      "[[ 0. 25.  0. 13.  9. 85.  1. 11.  5.  0.]]\n",
      "[[1.83853946e-05 4.78020261e-04 1.83853946e-05 2.57395525e-04\n",
      "  1.83853946e-04 1.58114394e-03 3.67707893e-05 2.20624736e-04\n",
      "  1.10312368e-04 1.83853946e-05]]\n",
      "2\n",
      "\n",
      "337\n",
      "[[ 0. 28.  7.  2.  9. 30.  3.  1. 11.  4.]]\n",
      "[[1.84121373e-05 5.33951981e-04 1.47297098e-04 5.52364118e-05\n",
      "  1.84121373e-04 5.70776256e-04 7.36485491e-05 3.68242746e-05\n",
      "  2.20945647e-04 9.20606864e-05]]\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# so now to calculate p(w|g) we need to sum by row the subsets of X_csr defined by group indeces\n",
    "# and then divide each element by # docs in group (length of group index range)\n",
    "def empirical_posterior(X_csr, train_index_ranges):\n",
    "    prob_stack = []\n",
    "    for start, end in train_index_ranges:\n",
    "        vec = X_csr[start:end, :].sum(axis=0)\n",
    "        print(end-start)\n",
    "        num_docs = end-start\n",
    "        print(vec[0, :10])\n",
    "        vec = vec/num_docs\n",
    "        print(vec[0, :10])\n",
    "        print(vec.ndim)\n",
    "        print()\n",
    "        prob_stack.append(vec.A.reshape(vec.shape[1]))\n",
    "\n",
    "    prob_stack = np.array(prob_stack)\n",
    "    return prob_stack\n",
    "\n",
    "\n",
    "def laplace_smoothed_posterior(X_csr, train_index_ranges, alpha=1):\n",
    "    \"\"\"add-one smoothing when alpha=1\"\"\"\n",
    "    prob_stack = []\n",
    "    for start, end in train_index_ranges:\n",
    "        vec = X_csr[start:end, :].sum(axis=0)\n",
    "        print(end-start)\n",
    "        num_docs = end-start\n",
    "        print(vec[0, :10])\n",
    "        vec = (vec+alpha)/(num_docs+alpha*X_csr.shape[1])\n",
    "        print(vec[0, :10])\n",
    "        print(vec.ndim)\n",
    "        print()\n",
    "        prob_stack.append(vec.A.reshape(vec.shape[1]))\n",
    "\n",
    "    prob_stack = np.array(prob_stack)\n",
    "    return prob_stack\n",
    "\n",
    "\n",
    "prob_stack = laplace_smoothed_posterior(X_csr, train_index_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 53975)\n",
      "[7.35213028e-05 6.24931074e-04 1.37852443e-03 9.19016285e-05\n",
      " 6.61691725e-04 5.69790097e-04 9.19016285e-05 3.67606514e-05\n",
      " 2.94085211e-04 9.00635959e-04]\n"
     ]
    }
   ],
   "source": [
    "print(prob_stack.shape)\n",
    "print(prob_stack[0, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prob_stack is a matrix shape (groups, vocab) that keeps the probabilities for number of documents having a word divided by number of documents in a group. Both empirical posterior and with Laplace smoothing has now been applied. About Laplace/Additive smoothing: https://en.wikipedia.org/wiki/Additive_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', 'to', 'in', 'and', 'of', 'is', 'it', 'that', 'for', 'this'],\n",
       "      dtype='<U79')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we will take a look at the most probable words. We assume that the most common words are common stopwords.\n",
    "\n",
    "token_probabilities = prob_stack.sum(axis=0)\n",
    "top_val_indeces = np.argsort(-token_probabilities)[:10]\n",
    "vocab_entries_for_top_indeces = np.array(vocab)[top_val_indeces]\n",
    "vocab_entries_for_top_indeces  # 10 most probable tokens in our vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04912827 0.04468292 0.04295694 0.04432907 0.04182715 0.04870425\n",
      " 0.03843853 0.04887348 0.04728229 0.04637036 0.0516335  0.06063393\n",
      " 0.0458135  0.05409486 0.05375905 0.05988108 0.05684757 0.06585345\n",
      " 0.05398022 0.04490958] 0.9999999999999998\n",
      "\n",
      "Group probabilities:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('talk.politics.mideast', 0.06585345013243205),\n",
       " ('sci.crypt', 0.06063392610148682),\n",
       " ('soc.religion.christian', 0.05988107553389996),\n",
       " ('talk.politics.guns', 0.05684757446077589),\n",
       " ('sci.med', 0.05409485886553029),\n",
       " ('talk.politics.misc', 0.05398022472323917),\n",
       " ('sci.space', 0.05375905481904335),\n",
       " ('rec.sport.hockey', 0.05163350093757131),\n",
       " ('alt.atheism', 0.049128268143443156),\n",
       " ('rec.autos', 0.04887348463781726),\n",
       " ('comp.windows.x', 0.048704249635702496),\n",
       " ('rec.motorcycles', 0.047282290318959724),\n",
       " ('rec.sport.baseball', 0.04637035644222927),\n",
       " ('sci.electronics', 0.04581349904539245),\n",
       " ('talk.religion.misc', 0.0449095802023898),\n",
       " ('comp.graphics', 0.044682917566578814),\n",
       " ('comp.sys.ibm.pc.hardware', 0.04432906815115269),\n",
       " ('comp.os.ms-windows.misc', 0.04295694258644816),\n",
       " ('comp.sys.mac.hardware', 0.041827145537828445),\n",
       " ('misc.forsale', 0.03843853215807878)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will take a look at prior probabilities P(group) based on the populated group-vocab matrix\n",
    "# the more densely-populated the group (more words in documents) the higher probabilities for tokens in vocab\n",
    "# and once tokens are summed the scalar tells the relative prior.\n",
    "# Records in prob_stack are already normalized by the number of documents in the set.\n",
    "# Prob: relative prior divided by sum of all priors\n",
    "group_priors = prob_stack.sum(axis=1)\n",
    "normalizing_term = group_priors.sum()\n",
    "group_priors = group_priors / normalizing_term\n",
    "print(group_priors, group_priors.sum())\n",
    "sorted_group_prior_indeces = np.argsort(-group_priors)\n",
    "sorted_priors = np.sort(-group_priors)\n",
    "group_prior_tuples = zip(np.array(groups)[sorted_group_prior_indeces], -sorted_priors)\n",
    "print(\"\\nGroup probabilities:\")\n",
    "list(group_prior_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 3\n",
    "\n",
    "- the probability tables for feature to label mapping is already stored in prob_stack\n",
    "- to get 'probabilities' (proportional to real probabilites) for each class, get product of features given class times prior of the class. \n",
    "- select largest value from previous step to be predicted class\n",
    "- evaluate by plotting confusion matrix and misclassification error\n",
    "- for both the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism 0.049128268143443156 (53975,)\n",
      "comp.graphics 0.044682917566578814 (53975,)\n",
      "comp.os.ms-windows.misc 0.04295694258644816 (53975,)\n",
      "comp.sys.ibm.pc.hardware 0.04432906815115269 (53975,)\n",
      "comp.sys.mac.hardware 0.041827145537828445 (53975,)\n",
      "comp.windows.x 0.048704249635702496 (53975,)\n",
      "misc.forsale 0.03843853215807878 (53975,)\n",
      "rec.autos 0.04887348463781726 (53975,)\n",
      "rec.motorcycles 0.047282290318959724 (53975,)\n",
      "rec.sport.baseball 0.04637035644222927 (53975,)\n",
      "rec.sport.hockey 0.05163350093757131 (53975,)\n",
      "sci.crypt 0.06063392610148682 (53975,)\n",
      "sci.electronics 0.04581349904539245 (53975,)\n",
      "sci.med 0.05409485886553029 (53975,)\n",
      "sci.space 0.05375905481904335 (53975,)\n",
      "soc.religion.christian 0.05988107553389996 (53975,)\n",
      "talk.politics.guns 0.05684757446077589 (53975,)\n",
      "talk.politics.mideast 0.06585345013243205 (53975,)\n",
      "talk.politics.misc 0.05398022472323917 (53975,)\n",
      "talk.religion.misc 0.0449095802023898 (53975,)\n"
     ]
    }
   ],
   "source": [
    "# prob_stack: prob distribution for tokens given group\n",
    "# --> for each prob vector and corresponding group_priors (same index)\n",
    "\n",
    "# construct a model holding these details (conditional probability vector for features, prior)\n",
    "naive_bayes_model = {}  # access by key=group_class, vals=(k,v) for k=(feat_probs, prior), v=(f_vec, prior)\n",
    "\n",
    "for i, row in enumerate(prob_stack):\n",
    "    group_class = groups[i]\n",
    "    g_prior = group_priors[i]\n",
    "    print(group_class, g_prior, row.shape)\n",
    "    naive_bayes_model[group_class] = {\n",
    "        \"feat_probs\": row,\n",
    "        \"prior\": g_prior\n",
    "    }\n",
    "    # now you have the group prior and conditional probability vector for features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we r gonna iterate each document in the training set and perform predictions using model from cell above.\n",
    "# we select the argmax of classes in the model to be classification prediction y_hat\n",
    "# all documents are in matrix X_csr.\n",
    "# iterate each of the known 'training set indeces' and perform prediction\n",
    "# store arrays y_true, y_pred each with dim (n, 20) where n is number of training samples\n",
    "\n",
    "\n",
    "def predict_for_multiple_records(X, model):\n",
    "    \"\"\"\n",
    "    The product of the feature probabilities tends to get very small which may cause numerical problems. \n",
    "    To avoid this, you can use a logarithmic scale to store the probabilities, i.e., initialize a \n",
    "    probability logp = log P (group) and add to it the term log P (wi | group) for all words wi occurring \n",
    "    in the document and the term log(1 − P (wi′ | group)) for all words wi′ that do not occur in the document. \n",
    "    The maximum probability class will have the highest logp value.\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    for i, row in enumerate(X):\n",
    "        row = row.A.reshape(-1)  # convert into np array and reshape into 1d vector to match model 'coefs'\n",
    "        # print(row.sum(), row.max(), row.min(), row.shape)\n",
    "        cls_probs = []\n",
    "        for cls, params in model.items():\n",
    "            present_mask = (row == 1)\n",
    "            absent_mask = (row == 0)\n",
    "            assert (present_mask.sum()+absent_mask.sum()) == row.shape[0], \"da fyck\"\n",
    "            \n",
    "            tokens_present_vec = params[\"feat_probs\"][present_mask]\n",
    "            tokens_absent_vec = params[\"feat_probs\"][absent_mask]\n",
    "            tmp_ones = np.ones(tokens_absent_vec.shape[0])\n",
    "            tokens_absent_vec = tmp_ones-tokens_absent_vec\n",
    "            \n",
    "            # transform feature probs into log probability to avoid numerical problems of extremely small numbers\n",
    "            tokens_present_vec = np.log(tokens_present_vec)\n",
    "            tokens_absent_vec = np.log(tokens_absent_vec)\n",
    "        \n",
    "            prob = params[\"prior\"]+np.sum(tokens_present_vec)+np.sum(tokens_absent_vec)\n",
    "            cls_probs.append(prob)\n",
    "        \n",
    "        preds.append(np.argmax(np.array(cls_probs)))\n",
    "    return preds\n",
    "\n",
    "\n",
    "def predictor(X_csr, index_ranges, naive_bayes_model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    i = 0\n",
    "    for start, end in index_ranges:\n",
    "        X_group = X_csr[start:end, :]\n",
    "        group_preds = predict_for_multiple_records(X_group, naive_bayes_model)\n",
    "        y_pred.extend(group_preds)\n",
    "        y_true.extend([i]*X_group.shape[0])  # i=group_idx, repeated m times, m=number of train samples for group i\n",
    "        i += 1\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = predictor(X_csr, train_index_ranges, naive_bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "accuracy: 0.8411945021259765\n",
      "miscls error: 0.15880549787402354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>362</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>381</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>346</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>487</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>480</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
       "0   296    0    0    0    0    0    0    0    0    0    0    1    0    0    0   \n",
       "1     0  362    4   13    1   17    2    1    0    0    1   91    0    1    4   \n",
       "2     1    4  381   19    0   21    0    0    0    0    0   70    0    2    1   \n",
       "3     0    2    0  433    0    3    2    0    0    0    0   66    0    1    1   \n",
       "4     0    3    1   12  346    3    0    1    1    0    0  122    3    3    0   \n",
       "5     0    1    3    1    0  492    0    0    0    0    0   25    0    0    0   \n",
       "6     0    0    2   35    3    0  289   17    1    1    4   82   11    4    7   \n",
       "7     0    0    0    0    0    2    0  485    0    1    0   10    0    0    0   \n",
       "8     0    1    0    0    0    0    4    1  492    0    0    6    0    1    0   \n",
       "9     0    0    0    0    0    2    0    1    0  487    8    5    0    2    1   \n",
       "10    0    0    0    0    0    0    0    1    0    0  526    2    1    0    0   \n",
       "11    0    0    0    0    0    0    0    0    0    0    0  530    0    0    0   \n",
       "12    0    1    0   11    1    0    0    1    0    0    0   60  424    0    4   \n",
       "13    0    0    0    0    0    0    0    0    0    0    0    5    1  508    0   \n",
       "14    0    1    0    0    0    1    0    0    0    0    0    2    0    0  520   \n",
       "15    1    0    0    1    0    0    0    0    0    0    0    0    0    0    0   \n",
       "16    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0   \n",
       "17    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "18    0    1    0    0    0    0    0    0    0    1    0    6    0    0    0   \n",
       "19   14    0    0    0    0    0    0    0    0    0    0    5    0    0    0   \n",
       "\n",
       "     15   16   17   18  19  \n",
       "0   106    0   28    0   0  \n",
       "1    20    1    4    0   0  \n",
       "2    10    0    3    1   0  \n",
       "3     9    3    7    0   0  \n",
       "4    16    2    3    0   0  \n",
       "5     4    1    3    1   0  \n",
       "6    18   11   37    0   0  \n",
       "7     8    7   17    1   0  \n",
       "8     6    9   15    0   0  \n",
       "9     9    4   14    0   0  \n",
       "10    1    0    5    1   0  \n",
       "11    0    1    2    0   0  \n",
       "12   10    3   16    0   0  \n",
       "13   13    2    4    0   0  \n",
       "14    5    1    2    0   0  \n",
       "15  534    0    2    0   0  \n",
       "16    4  480    4    0   0  \n",
       "17    2    0  504    0   0  \n",
       "18    8    5   28  367   0  \n",
       "19  210   18   36    3  51  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have got all the training set predictions and labels now and we can analyze the results\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "miscls_error = 1-accuracy\n",
    "print(groups)\n",
    "print(\"\\naccuracy:\", accuracy)\n",
    "print(\"miscls error:\", miscls_error)\n",
    "\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "pd.DataFrame(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = predictor(X_csr, test_index_ranges, naive_bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n",
      "accuracy: 0.6461937716262975\n",
      "miscls error: 0.35380622837370246\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  \\\n",
       "0   14   0   0   0   0   0   0   0   0   0   0   2   0   0   0  27   0   6   \n",
       "1    0  25   0   2   0   9   0   0   0   0   0  19   0   1   0   2   0   1   \n",
       "2    0   1  16   5   0   7   0   1   0   0   0  25   0   0   1   0   2   1   \n",
       "3    0   0   2  36   1   1   2   0   0   0   0  13   1   0   0   3   1   0   \n",
       "4    0   1   2   3  23   1   0   0   0   0   1  24   1   1   0   1   1   0   \n",
       "5    0   2   0   0   0  47   0   0   0   0   0   9   0   0   2   0   0   1   \n",
       "6    0   0   0   5   0   1  19   7   1   0   0  15   3   0   1   3   4   1   \n",
       "7    0   0   0   0   0   0   1  43   0   0   0   3   0   0   2   4   4   4   \n",
       "8    0   0   0   0   0   0   0   1  45   0   0   1   1   0   0   5   1   7   \n",
       "9    0   0   0   0   0   0   0   0   0  41   7   1   0   0   0   2   5   5   \n",
       "10   0   0   0   0   0   0   0   0   0   0  57   0   0   0   0   3   0   1   \n",
       "11   0   0   0   0   0   0   0   0   0   0   0  58   0   0   0   1   0   2   \n",
       "12   0   0   0   0   0   1   0   0   0   0   0  24  22   2   1   3   3   4   \n",
       "13   0   0   0   0   0   0   0   0   0   0   0   2   0  53   1   3   0   2   \n",
       "14   0   0   0   0   0   0   0   0   0   0   0   4   0   1  52   0   0   4   \n",
       "15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  56   1   4   \n",
       "16   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   1  48   3   \n",
       "17   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   0  56   \n",
       "18   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   3   2   7   \n",
       "19   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   9  11   \n",
       "\n",
       "    18  19  \n",
       "0    0   0  \n",
       "1    0   0  \n",
       "2    0   0  \n",
       "3    0   0  \n",
       "4    0   0  \n",
       "5    0   0  \n",
       "6    0   0  \n",
       "7    0   0  \n",
       "8    0   0  \n",
       "9    0   0  \n",
       "10   0   0  \n",
       "11   0   0  \n",
       "12   0   0  \n",
       "13   0   0  \n",
       "14   0   0  \n",
       "15   0   0  \n",
       "16   0   0  \n",
       "17   0   0  \n",
       "18  35   0  \n",
       "19   0   1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have test set results, lets present them below\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "miscls_error = 1-accuracy\n",
    "print(groups)\n",
    "print(\"\\naccuracy:\", accuracy)\n",
    "print(\"miscls error:\", miscls_error)\n",
    "\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "pd.DataFrame(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
